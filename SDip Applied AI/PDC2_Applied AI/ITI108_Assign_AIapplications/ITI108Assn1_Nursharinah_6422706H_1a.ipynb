{"cells":[{"cell_type":"markdown","source":["# ITI108 Assignment 1 - Nursharinah/6422706H - Student Answer Template"],"metadata":{"id":"J2eW6Hm16F_c"},"id":"J2eW6Hm16F_c"},{"cell_type":"markdown","source":["## **Assignment Overview**\n","\n","You are tasked with developing an AI solution that can audit customer service calls by analyzing audio files against specific criteria related to customer service performance. This project will integrate speech recognition, LLM to assess the quality of interactions between agents and customers. The final product should provide insights into key elements of customer service and generate a detailed audit report.\n","\n","You will be provided with the following audio files and text files contains the correct transcribes.\n","\n","Read the separate document for the assignment detials\n","\n","Please ensure all the results are printed on the cell for marking purpose."],"metadata":{"id":"gFEnUjjY6r-W"},"id":"gFEnUjjY6r-W"},{"cell_type":"code","source":["#Code for your solution\n","#provide some comments for better understand while marking your code"],"metadata":{"id":"dgLI9IUq6VwE"},"id":"dgLI9IUq6VwE","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Audio Transcription - Groq (Whisper Speech-To-Text)"],"metadata":{"id":"st6hQo2aXZdI"},"id":"st6hQo2aXZdI"},{"cell_type":"markdown","source":["## Install Libraries"],"metadata":{"id":"DjnUDRBdYAK9"},"id":"DjnUDRBdYAK9"},{"cell_type":"code","source":["\n","!pip install python-dotenv\n","!pip install gdown\n","!pip install groq\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdlFREJuoJHV","executionInfo":{"status":"ok","timestamp":1738953382967,"user_tz":-480,"elapsed":6456,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"a38a8799-2d73-4698-be32-99516fbbc083"},"id":"mdlFREJuoJHV","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"]}]},{"cell_type":"markdown","source":["## Download the Groq API key from Google Drive"],"metadata":{"id":"6LEzQypdpOPA"},"id":"6LEzQypdpOPA"},{"cell_type":"code","source":["\n","import gdown\n","\n","# URL to download the .txt file containing the API key\n","file_id = '1GjVKNAQo1KmrZL-qDBVgNnS3rp6Btdn5'\n","url = f'https://drive.google.com/uc?id={file_id}'\n","\n","# Specify the path where you want to save the file locally\n","output_path = 'groqAPIkey.txt'\n","\n","# Download the file\n","gdown.download(url, output_path, quiet=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"CqcAO4oKifrW","executionInfo":{"status":"ok","timestamp":1738953390526,"user_tz":-480,"elapsed":4507,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"8df00f84-bce3-407b-ef69-c49151939cc1"},"id":"CqcAO4oKifrW","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1GjVKNAQo1KmrZL-qDBVgNnS3rp6Btdn5\n","To: /content/groqAPIkey.txt\n","100%|██████████| 56.0/56.0 [00:00<00:00, 76.7kB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'groqAPIkey.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## Test the general-purpose LLM (for text-based tasks) with the following question\n","\n","\n","*   Which is the largest country by area in the world?"],"metadata":{"id":"xQ8CpJdFYX7o"},"id":"xQ8CpJdFYX7o"},{"cell_type":"code","source":["\n","# Read the API key from the downloaded file\n","with open(output_path, 'r') as file:\n","    api_key = file.read().strip()\n","\n","# Now use the API key to make requests\n","print(f\"Your API Key: {api_key[:10]}...\") # only show first 10 characters for security, to make sure key was properly loaded\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SU_3_jSUimBn","executionInfo":{"status":"ok","timestamp":1738953393459,"user_tz":-480,"elapsed":37,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"799e30b1-e1a8-4e20-ec2b-904237413ab3"},"id":"SU_3_jSUimBn","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Your API Key: gsk_nRqo1i...\n"]}]},{"cell_type":"code","source":["\n","import os\n","from groq import Groq\n","\n","# Load the Groq API Key from the file\n","with open(\"groqAPIkey.txt\", \"r\") as f:\n","    GROQ_API_KEY = f.read().strip()\n","\n","# Initialize the Groq Client\n","client = Groq(api_key=GROQ_API_KEY)\n","\n","# Select a Groq-compatible model (e.g., \"llama3-8b\" or \"gemma-7b\")\n","model = \"llama3-8b-8192\"\n","#model = \"mixtral-8x7b-32768\"\n","\n","def get_completion_from_messages(messages, model=model, temperature=0):\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,  # Controls randomness\n","    )\n","    return response.choices[0].message.content\n","\n","# Example query\n","print(get_completion_from_messages([{'role': 'user', 'content': 'Which is the largest country by area in the world?'}]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7VomZ2DFp5Dn","executionInfo":{"status":"ok","timestamp":1738953396597,"user_tz":-480,"elapsed":634,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"3483ee03-af2a-4609-ba32-9a0e6c50c672"},"id":"7VomZ2DFp5Dn","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The largest country by area in the world is Russia, which covers an area of approximately 17.1 million square kilometers (6.6 million square miles).\n"]}]},{"cell_type":"markdown","source":["## Create function for Extracted audio transcription (Whisper Speech To Text)"],"metadata":{"id":"fI3LmPfR4VC_"},"id":"fI3LmPfR4VC_"},{"cell_type":"code","source":["\n","#import os\n","#from groq import Groq\n","\n","# Load the Groq API Key from the file\n","with open(\"groqAPIkey.txt\", \"r\") as f:\n","    GROQ_API_KEY = f.read().strip()\n","\n","# Initialize the Groq Client\n","client = Groq(api_key=GROQ_API_KEY)\n","\n","# Whisper model for speech-to-text\n","model = \"whisper-large-v3\"\n","\n","def transcribe_audio(audio_file, model=model, prompt=\"\", temperature=0):\n","    with open(audio_file, \"rb\") as audio:\n","        response = client.audio.transcriptions.create(\n","            model=model,\n","            file=audio,\n","            prompt=prompt,\n","            temperature=temperature\n","        )\n","    return response.text  # Extract transcribed text\n"],"metadata":{"id":"dX4pfK7i4UYp","executionInfo":{"status":"ok","timestamp":1738953400975,"user_tz":-480,"elapsed":59,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"id":"dX4pfK7i4UYp","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Create function for Ground-truth audio transcription (WER - Original & Normalized)"],"metadata":{"id":"bu4ZWZ8qU6fI"},"id":"bu4ZWZ8qU6fI"},{"cell_type":"code","source":["\n","# Install JiWER\n","!pip install jiwer\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqPHyHK4WCT5","executionInfo":{"status":"ok","timestamp":1738953408614,"user_tz":-480,"elapsed":4512,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"bbd4e6b3-4233-4aae-fd26-c9fed71e590f"},"id":"sqPHyHK4WCT5","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n","Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.12.1)\n"]}]},{"cell_type":"code","source":["\n","# WER calculation - Original\n","from jiwer import wer\n","\n","def calculate_wer_Ori(ground_truth_file, predicted_text):\n","    \"\"\"Compute Word Error Rate (WER) using JiWER.\"\"\"\n","    with open(ground_truth_file, \"r\", encoding=\"utf-8\") as f:\n","        reference_text = f.read().strip()  # Read ground truth transcription\n","\n","    error_rate_Ori = wer(reference_text, predicted_text)\n","    return error_rate_Ori\n"],"metadata":{"id":"6BvGXphFU6MP","executionInfo":{"status":"ok","timestamp":1738953411523,"user_tz":-480,"elapsed":18,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"id":"6BvGXphFU6MP","execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","# WER calculation - with Preprocessing (to remove punctuation/case sensitivity)\n","# Preprocessing by Normalization\n","from jiwer import wer, Compose, RemovePunctuation, ToLowerCase, RemoveWhiteSpace\n","\n","# Define a transformation pipeline for normalization\n","transform = Compose([\n","    RemovePunctuation(),\n","    ToLowerCase(),\n","    RemoveWhiteSpace(replace_by_space=True),\n","])\n","\n","def calculate_wer_Norm(ground_truth_file, predicted_text):\n","    \"\"\"Compute Word Error Rate (WER) with normalization.\"\"\"\n","    with open(ground_truth_file, \"r\", encoding=\"utf-8\") as f:\n","        reference_text = f.read().strip()\n","\n","    # Apply normalization to both reference and hypothesis\n","    reference_text_Norm = transform(reference_text)\n","    predicted_text_Norm = transform(predicted_text)\n","\n","    error_rate_Norm = wer(reference_text_Norm, predicted_text_Norm)\n","    return error_rate_Norm\n"],"metadata":{"id":"-7WMBD2taSR6","executionInfo":{"status":"ok","timestamp":1738953414376,"user_tz":-480,"elapsed":588,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"id":"-7WMBD2taSR6","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Audit Transcription - AzureOpenAI (LLM Prompt Engineering)"],"metadata":{"id":"mOxfRfZNNuf2"},"id":"mOxfRfZNNuf2"},{"cell_type":"markdown","source":["## Install Libraries"],"metadata":{"id":"oE_7ETgHO8Iw"},"id":"oE_7ETgHO8Iw"},{"cell_type":"code","source":["\n","!pip install langchain openai tiktoken chromadb python-dotenv langchain_community\n","!pip install U langchain_openai\n","!pip install docarray\n","#!pip install python-dotenv\n","#!pip install gdown\n"],"metadata":{"id":"XJGGspIQO7mw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953464720,"user_tz":-480,"elapsed":7140,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"15bdb0ad-0fe9-44cd-8b9a-21d6ed352666"},"id":"XJGGspIQO7mw","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n","Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n","Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.16)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n","Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n","Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n","Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n","Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n","Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n","Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n","Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.0)\n","Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n","Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n","Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n","Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n","Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n","Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n","Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n","Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n","Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Requirement already satisfied: U in /usr/local/lib/python3.11/dist-packages (1.0)\n","Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.4)\n","Requirement already satisfied: revel>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from U) (0.9.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from U) (4.12.2)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.34)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.8.0)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_openai) (0.3.5)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_openai) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_openai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_openai) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_openai) (2.10.6)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n","Requirement already satisfied: blessed<2.0.0,>=1.19.1 in /usr/local/lib/python3.11/dist-packages (from revel>=0.9.0->U) (1.20.0)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from revel>=0.9.0->U) (0.4.6)\n","Requirement already satisfied: readchar<5.0.0,>=4.0.3 in /usr/local/lib/python3.11/dist-packages (from revel>=0.9.0->U) (4.2.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed<2.0.0,>=1.19.1->revel>=0.9.0->U) (0.2.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from blessed<2.0.0,>=1.19.1->revel>=0.9.0->U) (1.17.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_openai) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_openai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_openai) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_openai) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n","Requirement already satisfied: docarray in /usr/local/lib/python3.11/dist-packages (0.40.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from docarray) (1.26.4)\n","Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from docarray) (3.10.15)\n","Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from docarray) (2.10.6)\n","Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from docarray) (13.9.4)\n","Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.11/dist-packages (from docarray) (2.32.0.20241016)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from docarray) (0.9.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray) (2.18.0)\n","Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.11/dist-packages (from types-requests>=2.28.11.6->docarray) (2.3.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"]}]},{"cell_type":"markdown","source":["## Download the Azure OpenAI's .env into the colab virtual drive"],"metadata":{"id":"ll0JvQi9P9lz"},"id":"ll0JvQi9P9lz"},{"cell_type":"code","source":["\n","#import gdown\n","url = 'https://drive.google.com/file/d/1U43HPiy3dOLAZNZcw6TNxWmVw4MwM_4F/view?usp=drive_link'\n","output_path = '.env'\n","gdown.download(url, output_path, quiet=False,fuzzy=True)\n"],"metadata":{"id":"9tfUQDdaP9WT","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1738953473727,"user_tz":-480,"elapsed":4551,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"2aa57402-7e4d-4d7b-d1e4-839ebc75d45e"},"id":"9tfUQDdaP9WT","execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1U43HPiy3dOLAZNZcw6TNxWmVw4MwM_4F\n","To: /content/.env\n","100%|██████████| 222/222 [00:00<00:00, 631kB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'.env'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Load the .env to extract the API key, endpoint, deployment name, API version."],"metadata":{"id":"ZMsli2CWQJYY"},"id":"ZMsli2CWQJYY"},{"cell_type":"code","source":["\n","#import os\n","from dotenv import load_dotenv\n","\n","# Load .env file to environment\n","load_dotenv()\n","\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","print(f\"{OPENAI_API_KEY[:10]}...\") # only show first 10 characters for security, to make sure key was properly loaded\n","AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n","print(AZURE_ENDPOINT)\n","DEPLOYMENT_NAME = os.getenv('DEPLOYMENT_NAME')\n","print(DEPLOYMENT_NAME)\n","OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n","print(OPENAI_API_VERSION)\n"],"metadata":{"id":"iusAB7r0QI6T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953476150,"user_tz":-480,"elapsed":22,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"4e8c441e-f431-468f-e3e1-e380f0780909"},"id":"iusAB7r0QI6T","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["1ewvrdGS12...\n","https://nypopenai2.openai.azure.com/\n","gpt-4o-global\n","2024-07-01-preview\n"]}]},{"cell_type":"markdown","source":["## Test the general-purpose LLM"],"metadata":{"id":"Oxc9-xe4QS7T"},"id":"Oxc9-xe4QS7T"},{"cell_type":"code","source":["\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.schema import HumanMessage\n","\n","llm = AzureChatOpenAI(deployment_name=DEPLOYMENT_NAME, openai_api_version=OPENAI_API_VERSION, openai_api_key=OPENAI_API_KEY, openai_api_base=AZURE_ENDPOINT, temperature=0.9)\n","\n","msg = HumanMessage(content=\"Explain step by step. How old is the president of USA?\")\n","print(llm(messages=[msg]))\n","\n","print(llm.invoke([{'role':'user', 'content':'Which is the largest country by area in the world?'}]).content)\n"],"metadata":{"id":"PcdSVlhdQSkk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953486364,"user_tz":-480,"elapsed":5979,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"1433a51a-0807-4c9f-a7c4-892da2649e71"},"id":"PcdSVlhdQSkk","execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-1359f3abe7a3>:4: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n","  llm = AzureChatOpenAI(deployment_name=DEPLOYMENT_NAME, openai_api_version=OPENAI_API_VERSION, openai_api_key=OPENAI_API_KEY, openai_api_base=AZURE_ENDPOINT, temperature=0.9)\n","/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://nypopenai2.openai.azure.com/ to https://nypopenai2.openai.azure.com/openai.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://nypopenai2.openai.azure.com/ to https://nypopenai2.openai.azure.com/openai.\n","  warnings.warn(\n","<ipython-input-15-1359f3abe7a3>:7: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  print(llm(messages=[msg]))\n"]},{"output_type":"stream","name":"stdout","text":["content=\"To determine the current age of the President of the United States, follow these steps:\\n\\n1. **Identify the current President**: As of 2023, the President of the United States is Joe Biden.\\n\\n2. **Find the birthdate of the President**: Joe Biden was born on November 20, 1942.\\n\\n3. **Calculate the age**: \\n   - Identify the current year: 2023.\\n   - Calculate the difference between the current year and the birth year: 2023 - 1942 = 81 years.\\n   - Check if the birthdate has occurred this year by comparing the current date to the birth date (November 20):\\n     - If today’s date is before November 20, Biden is still 80.\\n     - If today’s date is on or after November 20, Biden has turned 81.\\n\\nLet's assume today's date is October 1, 2023:\\n- Since today's date is before November 20, Joe Biden would still be 80 years old.\\n\\nIf the date is after November 20, such as December 1, 2023:\\n- Joe Biden would be 81 years old.\\n\\nThus, as of October 2023, Joe Biden is 80 years old. He will turn 81 on November 20, 2023.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 269, 'prompt_tokens': 20, 'total_tokens': 289, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_65792305e4', 'finish_reason': 'stop', 'logprobs': None} id='run-fe99e846-8c57-4ab7-8515-e5c139188693-0'\n","The largest country by area in the world is Russia. It spans over 17 million square kilometers (approximately 6.6 million square miles).\n"]}]},{"cell_type":"markdown","source":["## Define the Audit Prompt Template"],"metadata":{"id":"oN-YtdsINQ0d"},"id":"oN-YtdsINQ0d"},{"cell_type":"code","source":["\n","from langchain.prompts import PromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# Define a prompt template for auditing customer service conversations\n","audit_prompt = PromptTemplate(\n","    input_variables=[\"transcription\"],\n","    template=(\n","        \"You are an AI auditor analyzing a conversation between a customer service agent and a customer. \"\n","        \"Your task is to label the speakers, check compliance with 9 audit criteria, and format the audit report in JSON.\\n\\n\"\n","        \"### Conversation:\\n{transcription}\\n\\n\"\n","        \"### Audit Criteria:\\n\"\n","        \"1. **Introduction** – Did the agent introduce themselves before the conversation?\\n\"\n","        \"2. **Acquire Customer Information** – Did the agent gather customer details before engaging?\\n\"\n","        \"3. **Politeness and Respect** – Was the agent polite and respectful during the interaction?\\n\"\n","        \"4. **Empathy and Understanding** – Did the agent demonstrate empathy while addressing inquiries?\\n\"\n","        \"5. **Gratitude** – Did the agent express gratitude when the customer showed interest?\\n\"\n","        \"6. **Provide Conclusion from Customer Request** – Did the agent summarize the customer's request?\\n\"\n","        \"7. **Clarifying Questions** – Did the agent ask clarifying questions if the customer was unclear?\\n\"\n","        \"8. **Clarity of Language** – Was the agent’s language clear, concise, and easy to understand?\\n\"\n","        \"9. **Relevance of Information** – Did the agent provide relevant information to the customer’s request?\\n\\n\"\n","        \"### Audit Output Format (JSON Example):\\n\"\n","        \"{{{{\\n\"\n","        '  \"audit_results\": [\\n'\n","        '    {{\"criteria\": \"Introduction\", \"audit_reason\": \"The agent introduced themselves at the start.\", \"result\": \"Pass\"}},\\n'\n","        '    {{\"criteria\": \"Politeness and Respect\", \"audit_reason\": \"The agent was polite and used professional language.\", \"result\": \"Pass\"}}\\n'\n","        \"  ]\\n\"\n","        \"}}}}\\n\\n\"\n","        \"### Task Instructions:\\n\"\n","        \"1. **Label the speakers** as 'Agent:' and 'Customer:'.\\n\"\n","        \"2. **Check each criterion** and provide an explanation (Audit Reason) for the decision.\\n\"\n","        \"3. **Format the final audit results as JSON**.\\n\\n\"\n","        \"Now, generate the structured audit report in JSON format.\"\n","    ),\n",")\n"],"metadata":{"id":"Pl4UMbvKe2LZ","executionInfo":{"status":"ok","timestamp":1738953488783,"user_tz":-480,"elapsed":49,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"id":"Pl4UMbvKe2LZ","execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","# Create a langchain pipeline to process the audit prompt using AzureChatOpenAI\n","audit_chain = audit_prompt | llm | StrOutputParser()\n"],"metadata":{"id":"6kyfh0eKNQU5","executionInfo":{"status":"ok","timestamp":1738953491413,"user_tz":-480,"elapsed":30,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"id":"6kyfh0eKNQU5","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Test with each of the given audio files\n","\n","**Esure you printout the results in each cell for marking**"],"metadata":{"id":"vVNjZEbC8hSq"},"id":"vVNjZEbC8hSq"},{"cell_type":"markdown","source":["## 1. Custom-Home-Builder.mp3"],"metadata":{"id":"VqEVCec07J0B"},"id":"VqEVCec07J0B"},{"cell_type":"markdown","source":["1. Input audio file to generate the transcript - print the transcript"],"metadata":{"id":"Zk9B0hCo83bz"},"id":"Zk9B0hCo83bz"},{"cell_type":"code","source":["\n","# Example Usage\n","audio_file1 = \"Custom-Home-Builder.mp3\"  # Path to audio file\n","\n","# Step 1: Get transcribed text\n","predicted_transcription1 = transcribe_audio(audio_file1)\n","\n","# Print Result\n","print(\"Predicted Transcription:\", predicted_transcription1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"do5qFr113Uww","executionInfo":{"status":"ok","timestamp":1738951015641,"user_tz":-480,"elapsed":1594,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"ced38cd4-8bbd-4c3b-8616-62a571211620"},"id":"do5qFr113Uww","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Transcription:  Call is now being recorded. Good afternoon, Elkins Builders. Yeah, hi. I'm calling to speak to someone about building a house on a property I'm looking to purchase. Oh, okay, great. Let me get your name. What's your first name, please? Kenny. And your last name? Lindstrom. It's L-I-N-D-S-T-R-O-M. Thank you. And may I have your callback number? It's 610- That's 610-265-1715. That's 610-265-1715? Yes. And where is the property that you're looking for an estimate on? It's in Westchester. I haven't purchased the land yet. I'd like to see if I could get an estimate or have them take a look at it before I do. Okay, no problem. Is there a good time to reach you with this number, or is that an anytime? time. That's my cell phone. If they could call me back today, that would be great. Okay, no problem. I'll pass your message along and somebody should be getting back to you this afternoon. Great. Thank you so much. You're welcome. And thank you for calling Elkins Builders. Bye-bye. you\n"]}]},{"cell_type":"markdown","source":["2. Word Error Rate(WER)\n","\n","Use this module jiwer to compute the WER - print the WER result"],"metadata":{"id":"9qXTo7SH9Qce"},"id":"9qXTo7SH9Qce"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file1 = \"Custom-Home-Builder.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Original\n","wer_score1 = calculate_wer_Ori(ground_truth_file1, predicted_transcription1)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Original:\", wer_score1)\n"],"metadata":{"id":"Euj60BYu-BoX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738951020816,"user_tz":-480,"elapsed":54,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"66dd8ce9-79ad-4447-87c9-b168bd3ee408"},"id":"Euj60BYu-BoX","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Original: 0.05202312138728324\n"]}]},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file1 = \"Custom-Home-Builder.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Normalized\n","wer_score1 = calculate_wer_Norm(ground_truth_file1, predicted_transcription1)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Normalized:\", wer_score1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrGdHLI-cuBU","executionInfo":{"status":"ok","timestamp":1738951025720,"user_tz":-480,"elapsed":28,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"855a7a9c-8dc6-4dbd-cb8e-c50e58d9f3dc"},"id":"CrGdHLI-cuBU","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Normalized: 0.03468208092485549\n"]}]},{"cell_type":"markdown","source":["3. Use the transcript with speakers label perform audit with the criteria then generate the report - print the result"],"metadata":{"id":"LV5SMGvu-uRK"},"id":"LV5SMGvu-uRK"},{"cell_type":"code","source":["\n","# Run the Audit on predicted_transcription1\n","import json\n","\n","# Use the predicted transcription from your speech-to-text model\n","audit_result_json1 = audit_chain.invoke({\"transcription\": predicted_transcription1})\n","\n","#Check if output is empty (for debugging)\n","#print(\"Audit Result JSON Output:\", audit_result_json1)\n"],"metadata":{"id":"UwVe1Teo_ZdV","executionInfo":{"status":"ok","timestamp":1738951099380,"user_tz":-480,"elapsed":6471,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"id":"UwVe1Teo_ZdV","execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["4. Export the report - print the result"],"metadata":{"id":"iScpFiDwhWCh"},"id":"iScpFiDwhWCh"},{"cell_type":"code","source":["\n","#import json\n","\n","# Raw output from the LLM\n","raw_output1 = audit_result_json1\n","\n","# Clean the output by stripping code block markers\n","cleaned_json1 = raw_output1.strip(\"```json\").strip(\"```\").strip()\n","\n","# Try parsing the cleaned JSON safely\n","try:\n","    audit_result = json.loads(cleaned_json1)\n","    print(json.dumps(audit_result, indent=4))  # Pretty print the output\n","except json.JSONDecodeError as e:\n","    print(\"JSON Decode Error:\", e)\n","    print(\"Raw Output:\", cleaned_json1)  # Print the raw output for debugging\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODNx9sbngyiB","executionInfo":{"status":"ok","timestamp":1738951106423,"user_tz":-480,"elapsed":33,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"dc40e9ab-538f-4c37-cacc-8c5986496852"},"id":"ODNx9sbngyiB","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"audit_results\": [\n","        {\n","            \"criteria\": \"Introduction\",\n","            \"audit_reason\": \"The agent did not introduce themselves at the start of the call.\",\n","            \"result\": \"Fail\"\n","        },\n","        {\n","            \"criteria\": \"Acquire Customer Information\",\n","            \"audit_reason\": \"The agent gathered the customer's name, phone number, and property location before engaging.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Politeness and Respect\",\n","            \"audit_reason\": \"The agent used polite language throughout the conversation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Empathy and Understanding\",\n","            \"audit_reason\": \"The agent acknowledged the customer's request and demonstrated understanding by ensuring follow-up.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Gratitude\",\n","            \"audit_reason\": \"The agent thanked the customer at the end of the call.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Provide Conclusion from Customer Request\",\n","            \"audit_reason\": \"The agent confirmed that a message would be passed along and that somebody would get back to the customer.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarifying Questions\",\n","            \"audit_reason\": \"The agent asked for clarifications on the customer's contact number and scheduling.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarity of Language\",\n","            \"audit_reason\": \"The agent's language was clear, concise, and easy to understand.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Relevance of Information\",\n","            \"audit_reason\": \"The agent provided relevant information about follow-up to the customer's request.\",\n","            \"result\": \"Pass\"\n","        }\n","    ]\n","}\n"]}]},{"cell_type":"markdown","source":["## 2. Inbound-sales-audio-sample.mp3"],"metadata":{"id":"IWtOS1a47JdV"},"id":"IWtOS1a47JdV"},{"cell_type":"markdown","source":["1. Input audio file to generate the transcript - print the transcript"],"metadata":{"id":"0kdrIoKi_jbo"},"id":"0kdrIoKi_jbo"},{"cell_type":"code","source":["\n","# Example Usage\n","audio_file2 = \"Inbound-sales-audio-sample.mp3\"  # Path to audio file\n","\n","# Step 1: Get transcribed text\n","predicted_transcription2 = transcribe_audio(audio_file2)\n","\n","# Print Result\n","print(\"Predicted Transcription:\", predicted_transcription2)\n"],"metadata":{"id":"2RFUfW2T9Jf9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952103282,"user_tz":-480,"elapsed":3505,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"01e53023-bd7d-4eb5-e98e-8e212b32c2fa"},"id":"2RFUfW2T9Jf9","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Transcription:  Thank you for calling Brentburg. This is Jessica. How may I help you? Hi, Jessica. My name is John and I'm from Sydney, Australia, and I run a tech marketplace business, a startup, and I'm run off my feet at the moment. I'm looking for someone to help me get a virtual assistant. Is that something you can help me with? Yes, definitely, John. Thank you so much for that information. May I know what are the different tasks this virtual assistant would be doing? Yeah, I just really need basic administrative work. I need someone to do my email management. I need someone to manage my calendar, do some scheduling for me, maybe book some travel if I need to from time to time, some data entry, some pretty basic stuff just to help me with work that I shouldn't be focused on while I'm trying to launch this new tech company. Yes, definitely. I can help you out with that. Well, you said that what you're looking for is someone who can do email management, calendar management, data entry, a little bit of reservations and bookings for you. Are there any other tasks that you think this person would be doing? Look, they've got to have a decent speaking voice. That's one of the things they might need to call people on my behalf. So they need to sound professional. They also need to write professionally as well. So I need someone who can read, who sound well and write well. Great. So we would look for someone with excellent communication skills both verbal and written All right Yes I can definitely help you out with that I can assign an administrative assistant for you Is this for a full or a part role How many hours a week is part-time? Our minimum for part-time roles are 20 hours a week, which is like Mondays through Fridays, four hours in a day. And how many for full-time? For full-time, it's 40 hours a week, Mondays through Fridays. So about nine hours a day with one hour lunch. Okay, that sounds more like what I need. And what's the approximate rate? At this stage, look, I'm not looking to get someone immediately. I probably need someone in the next month or so. So at the moment, I'm just exploring pricing. So if you just give me an approximate range, and if you can email me some information, that would be great for what I need today. Okay, well, here on, I can provide you the rate, and then I will definitely email you all the information that we have discussed and more about our company. The rate is $7.50 to $9 per hour, AUD, XGSE. How does that sound to you? That sounds excellent. If you can send me an email to john.gartner, G-A-R-T-N-E-R, at gmail.com, and I will read that and review it, and I'll come back with any questions, or I might book in another time with you to have a chat. Lovely. I definitely do that. and I'll follow up with you in a couple of days. Is that okay? Yeah, that would be great. Thank you for your time. Thank you for your time. Have a lovely rest of your day. Bye-bye.\n"]}]},{"cell_type":"markdown","source":["2. Word Error Rate(WER)\n","\n","Use this module jiwer to compute the WER - print the WER result"],"metadata":{"id":"QOyKnkPv_jbp"},"id":"QOyKnkPv_jbp"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file2 = \"Inbound-sales-audio-sample.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Original\n","wer_score2 = calculate_wer_Ori(ground_truth_file2, predicted_transcription2)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Original:\", wer_score2)\n"],"metadata":{"id":"Tnkw-8u1_jbp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952107265,"user_tz":-480,"elapsed":21,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"c0d53552-6dfe-4874-8e00-38e9fcec696b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Original: 0.05514705882352941\n"]}],"id":"Tnkw-8u1_jbp"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file2 = \"Inbound-sales-audio-sample.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Normalized\n","wer_score2 = calculate_wer_Norm(ground_truth_file2, predicted_transcription2)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Normalized:\", wer_score2)\n"],"metadata":{"id":"GB1NZOkynVbO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952110347,"user_tz":-480,"elapsed":60,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"254df73b-3bf8-4346-919e-9f1557025a35"},"id":"GB1NZOkynVbO","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Normalized: 0.014678899082568808\n"]}]},{"cell_type":"markdown","source":["3. Use the transcript with speakers label perform audit with the criteria then generate the report - print the result"],"metadata":{"id":"16jR3co8_jbq"},"id":"16jR3co8_jbq"},{"cell_type":"code","source":["\n","# Run the Audit on predicted_transcription2\n","import json\n","\n","# Use the predicted transcription from your speech-to-text model\n","audit_result_json2 = audit_chain.invoke({\"transcription\": predicted_transcription2})\n","\n","#Check if output is empty (for debugging)\n","#print(\"Audit Result JSON Output:\", audit_result_json2)\n"],"metadata":{"id":"nx9NJ4Ak_jbq","executionInfo":{"status":"ok","timestamp":1738952170765,"user_tz":-480,"elapsed":4593,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"execution_count":18,"outputs":[],"id":"nx9NJ4Ak_jbq"},{"cell_type":"markdown","source":["4. Export the report - print the result"],"metadata":{"id":"WxBoivFghxlL"},"id":"WxBoivFghxlL"},{"cell_type":"code","source":["\n","#import json\n","\n","# Raw output from the LLM\n","raw_output2 = audit_result_json2\n","\n","# Clean the output by stripping code block markers\n","cleaned_json2 = raw_output2.strip(\"```json\").strip(\"```\").strip()\n","\n","# Try parsing the cleaned JSON safely\n","try:\n","    audit_result = json.loads(cleaned_json2)\n","    print(json.dumps(audit_result, indent=4))  # Pretty print the output\n","except json.JSONDecodeError as e:\n","    print(\"JSON Decode Error:\", e)\n","    print(\"Raw Output:\", cleaned_json2)  # Print the raw output for debugging\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44hSN4LGhxUa","executionInfo":{"status":"ok","timestamp":1738952173439,"user_tz":-480,"elapsed":18,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"2cac076a-a991-4dfb-b8d5-93728c193994"},"id":"44hSN4LGhxUa","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"audit_results\": [\n","        {\n","            \"criteria\": \"Introduction\",\n","            \"audit_reason\": \"The agent introduced themselves at the start.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Acquire Customer Information\",\n","            \"audit_reason\": \"The agent gathered customer details by asking about the tasks the virtual assistant would be doing.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Politeness and Respect\",\n","            \"audit_reason\": \"The agent was polite and used professional language throughout the conversation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Empathy and Understanding\",\n","            \"audit_reason\": \"The agent demonstrated understanding and attentiveness to the customer's needs and concerns.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Gratitude\",\n","            \"audit_reason\": \"The agent expressed gratitude when the customer shared information about their needs.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Provide Conclusion from Customer Request\",\n","            \"audit_reason\": \"The agent summarized the customer's request accurately and confirmed the services that can be provided.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarifying Questions\",\n","            \"audit_reason\": \"The agent asked clarifying questions to ensure they understood the tasks required by the customer.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarity of Language\",\n","            \"audit_reason\": \"The agent\\u2019s language was clear, concise, and easy to understand.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Relevance of Information\",\n","            \"audit_reason\": \"The agent provided relevant information regarding the part-time and full-time roles, as well as the pricing.\",\n","            \"result\": \"Pass\"\n","        }\n","    ]\n","}\n"]}]},{"cell_type":"markdown","source":["## 3. Local-Plumber.mp3"],"metadata":{"id":"DmBOTrTj7_CP"},"id":"DmBOTrTj7_CP"},{"cell_type":"markdown","source":["1. Input audio file to generate the transcript - print the transcript"],"metadata":{"id":"C4hlPqwV_oHm"},"id":"C4hlPqwV_oHm"},{"cell_type":"code","source":["\n","# Example Usage\n","audio_file3 = \"Local-Plumber.mp3\"  # Path to audio file\n","\n","# Step 1: Get transcribed text\n","predicted_transcription3 = transcribe_audio(audio_file3)\n","\n","# Print Result\n","print(\"Predicted Transcription:\", predicted_transcription3)\n"],"metadata":{"id":"ccz3-S5B9UrZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952369518,"user_tz":-480,"elapsed":1728,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"7699bd8d-b0e6-4e5f-c137-78a993163054"},"id":"ccz3-S5B9UrZ","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Transcription:  Call is now being recorded. ABC Plumbing and Heating, this is Betty. Hi Betty, I'm having a problem with my sewer drain. Oh, I'm so sorry to hear that, sir. Would you like me to get a hold of the plumber for you? Do you know how much it's going to cost? Unfortunately, I wouldn't be able to quote prices, but I can get a hold of someone who would be able to give you a better idea. I'm getting a backup throughout the entire house. Are you a client of ABC? I did use them before to put in my garbage disposal, but nothing major like this. Okay. Let me get your name and number, and I can patch you right through to the plumber. Your name, sir? Mike Barry. Would you spell your last name for me, please? That's B-A-R-R-Y. Okay. And your callback number? 610-265-1714. Okay, that's 610-265-1714. Yes, will he call me right back? Actually, Mr. Berry, I'm going to call him right now and patch you directly through to the plumber. Would you stay on the line for a moment? Oh, sure. Awesome. Thank you. Okay, hold on.\n"]}]},{"cell_type":"markdown","source":["2. Word Error Rate(WER)\n","\n","Use this module jiwer to compute the WER - print the WER result"],"metadata":{"id":"9FAN4eeU_oHn"},"id":"9FAN4eeU_oHn"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file3 = \"Local-Plumber.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Original\n","wer_score3 = calculate_wer_Ori(ground_truth_file3, predicted_transcription3)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Original:\", wer_score3)\n"],"metadata":{"id":"X227N0_X_oHn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952376654,"user_tz":-480,"elapsed":52,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"b7ae8235-0d97-43bc-f596-48a1982d2cc6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Original: 0.05181347150259067\n"]}],"id":"X227N0_X_oHn"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file3 = \"Local-Plumber.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Normalized\n","wer_score3 = calculate_wer_Norm(ground_truth_file3, predicted_transcription3)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Normalized:\", wer_score3)\n"],"metadata":{"id":"9Yt9oW5Cn9VZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952381705,"user_tz":-480,"elapsed":54,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"c07c351a-42dc-4dc8-fb31-3846e81c1a06"},"id":"9Yt9oW5Cn9VZ","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Normalized: 0.0\n"]}]},{"cell_type":"markdown","source":["3. Use the transcript with speakers label perform audit with the criteria then generate the report - print the result"],"metadata":{"id":"3YjMl9Ro_oHn"},"id":"3YjMl9Ro_oHn"},{"cell_type":"code","source":["\n","# Run the Audit on predicted_transcription3\n","import json\n","\n","# Use the predicted transcription from your speech-to-text model\n","audit_result_json3 = audit_chain.invoke({\"transcription\": predicted_transcription3})\n","\n","#Check if output is empty (for debugging)\n","#print(\"Audit Result JSON Output:\", audit_result_json3)\n"],"metadata":{"id":"h8NqzLnS_oHn","executionInfo":{"status":"ok","timestamp":1738952482231,"user_tz":-480,"elapsed":10657,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"execution_count":19,"outputs":[],"id":"h8NqzLnS_oHn"},{"cell_type":"markdown","source":["4. Export the report - print the result"],"metadata":{"id":"UB2L8tAth0Wo"},"id":"UB2L8tAth0Wo"},{"cell_type":"code","source":["\n","#import json\n","\n","# Raw output from the LLM\n","raw_output3 = audit_result_json3\n","\n","# Clean the output by stripping code block markers\n","cleaned_json3 = raw_output3.strip(\"```json\").strip(\"```\").strip()\n","\n","# Try parsing the cleaned JSON safely\n","try:\n","    audit_result = json.loads(cleaned_json3)\n","    print(json.dumps(audit_result, indent=4))  # Pretty print the output\n","except json.JSONDecodeError as e:\n","    print(\"JSON Decode Error:\", e)\n","    print(\"Raw Output:\", cleaned_json3)  # Print the raw output for debugging\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDyhChcxh0Ff","executionInfo":{"status":"ok","timestamp":1738952485542,"user_tz":-480,"elapsed":56,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"9a78a734-9add-4ddf-af12-83a8381c3a2a"},"id":"WDyhChcxh0Ff","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"conversation\": [\n","        {\n","            \"Agent\": \"Call is now being recorded. ABC Plumbing and Heating, this is Betty.\"\n","        },\n","        {\n","            \"Customer\": \"Hi Betty, I'm having a problem with my sewer drain.\"\n","        },\n","        {\n","            \"Agent\": \"Oh, I'm so sorry to hear that, sir. Would you like me to get a hold of the plumber for you?\"\n","        },\n","        {\n","            \"Customer\": \"Do you know how much it's going to cost?\"\n","        },\n","        {\n","            \"Agent\": \"Unfortunately, I wouldn't be able to quote prices, but I can get a hold of someone who would be able to give you a better idea.\"\n","        },\n","        {\n","            \"Customer\": \"I'm getting a backup throughout the entire house.\"\n","        },\n","        {\n","            \"Agent\": \"Are you a client of ABC?\"\n","        },\n","        {\n","            \"Customer\": \"I did use them before to put in my garbage disposal, but nothing major like this.\"\n","        },\n","        {\n","            \"Agent\": \"Okay. Let me get your name and number, and I can patch you right through to the plumber. Your name, sir?\"\n","        },\n","        {\n","            \"Customer\": \"Mike Barry.\"\n","        },\n","        {\n","            \"Agent\": \"Would you spell your last name for me, please?\"\n","        },\n","        {\n","            \"Customer\": \"That's B-A-R-R-Y.\"\n","        },\n","        {\n","            \"Agent\": \"Okay. And your callback number?\"\n","        },\n","        {\n","            \"Customer\": \"610-265-1714.\"\n","        },\n","        {\n","            \"Agent\": \"Okay, that's 610-265-1714.\"\n","        },\n","        {\n","            \"Customer\": \"Yes, will he call me right back?\"\n","        },\n","        {\n","            \"Agent\": \"Actually, Mr. Barry, I'm going to call him right now and patch you directly through to the plumber. Would you stay on the line for a moment?\"\n","        },\n","        {\n","            \"Customer\": \"Oh, sure.\"\n","        },\n","        {\n","            \"Agent\": \"Awesome. Thank you. Okay, hold on.\"\n","        }\n","    ],\n","    \"audit_results\": [\n","        {\n","            \"criteria\": \"Introduction\",\n","            \"audit_reason\": \"The agent introduced themselves at the start.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Acquire Customer Information\",\n","            \"audit_reason\": \"The agent gathered the customer's name and contact number before engaging further.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Politeness and Respect\",\n","            \"audit_reason\": \"The agent was polite and used professional language throughout the conversation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Empathy and Understanding\",\n","            \"audit_reason\": \"The agent expressed empathy by saying they were sorry to hear about the customer's issue.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Gratitude\",\n","            \"audit_reason\": \"The agent thanked the customer at the end of the conversation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Provide Conclusion from Customer Request\",\n","            \"audit_reason\": \"The agent concluded the call by summarizing the action they would take, i.e., patching the customer through to the plumber.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarifying Questions\",\n","            \"audit_reason\": \"The agent asked the customer to spell their last name and repeated the callback number to ensure accuracy.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarity of Language\",\n","            \"audit_reason\": \"The agent\\u2019s language was clear, concise, and easy to understand.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Relevance of Information\",\n","            \"audit_reason\": \"The agent provided relevant information regarding the next steps and addressed the customer's immediate concern.\",\n","            \"result\": \"Pass\"\n","        }\n","    ]\n","}\n"]}]},{"cell_type":"markdown","source":["## 4. Property-Management-Office.mp3"],"metadata":{"id":"XiO04CSC8D_m"},"id":"XiO04CSC8D_m"},{"cell_type":"markdown","source":["1. Input audio file to generate the transcript - print the transcript"],"metadata":{"id":"i0dtdbzf_xTa"},"id":"i0dtdbzf_xTa"},{"cell_type":"code","source":["\n","# Example Usage\n","audio_file4 = \"Property-Management-Office.mp3\"  # Path to audio file\n","\n","# Step 1: Get transcribed text\n","predicted_transcription4 = transcribe_audio(audio_file4)\n","\n","# Print Result\n","print(\"Predicted Transcription:\", predicted_transcription4)\n"],"metadata":{"id":"hpok9h8R9bWZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952676711,"user_tz":-480,"elapsed":2700,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"5400a857-be6c-4c45-a570-3dae0e21cd47"},"id":"hpok9h8R9bWZ","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Transcription:  Call is now being recorded. Good evening, Kingswood Apartments. This is Alex. How may I help you? Hey, yeah, I'm in apartment 104 on the first floor. I'm calling to complain about my neighbors. Okay, what seems to be the problem, sir? It's very late. I just got my newborn baby to sleep, and they're being loud again. I brought this to their attention several times, but they never, you know, never stops. Okay, I'm very sorry about that. Just let me take down your contact information and I'll contact the landlord right away to get this all straightened out. Okay, my name is Jeff Matthews. Okay, Mr. Matthews, can you spell that for me? First name is Jeff, J-E-F-F. Last name is Matthews, M-A-T-T-H-E-W-S. Okay, Mr. Matthews, can I have the best number you can be reached at and also your apartment number again? Sure, it's 610-265-1714, and I'm in apartment 104 on the first floor. Okay, I have 610-265-1714 and apartment 104. Yes. All right, Mr. Matthews, I'm going to pass this information on to the landlord right away, and he'll be contacting you shortly. Is there anything else I can help you with today? No, that's all. Thank you. Thank you very much. Have a great night. You too.\n"]}]},{"cell_type":"markdown","source":["2. Word Error Rate(WER)\n","\n","Use this module jiwer to compute the WER - print the WER result"],"metadata":{"id":"C4l4CEgl_xTb"},"id":"C4l4CEgl_xTb"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file4 = \"Property-Management-Office.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Original\n","wer_score4 = calculate_wer_Ori(ground_truth_file4, predicted_transcription4)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Original:\", wer_score4)\n"],"metadata":{"id":"rILHWstE_xTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952680052,"user_tz":-480,"elapsed":19,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"e783a177-eaa3-453b-dcbc-436e16ebd44a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Original: 0.018957345971563982\n"]}],"id":"rILHWstE_xTb"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file4 = \"Property-Management-Office.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Normalized\n","wer_score4 = calculate_wer_Norm(ground_truth_file4, predicted_transcription4)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Normalized:\", wer_score4)\n"],"metadata":{"id":"2K-S9a38n_EV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738952682106,"user_tz":-480,"elapsed":40,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"0914cd4c-2a71-4c2e-ce3b-2d9608e8db33"},"id":"2K-S9a38n_EV","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Normalized: 0.014218009478672985\n"]}]},{"cell_type":"markdown","source":["3. Use the transcript with speakers label perform audit with the criteria then generate the report - print the result"],"metadata":{"id":"yks-wZYY_xTb"},"id":"yks-wZYY_xTb"},{"cell_type":"code","source":["\n","# Run the Audit on predicted_transcription4\n","import json\n","\n","# Use the predicted transcription from your speech-to-text model\n","audit_result_json4 = audit_chain.invoke({\"transcription\": predicted_transcription4})\n","\n","#Check if output is empty (for debugging)\n","#print(\"Audit Result JSON Output:\", audit_result_json4)\n"],"metadata":{"id":"8d32cWp0_xTb","executionInfo":{"status":"ok","timestamp":1738952751811,"user_tz":-480,"elapsed":4504,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"execution_count":18,"outputs":[],"id":"8d32cWp0_xTb"},{"cell_type":"markdown","source":["4. Export the report - print the result"],"metadata":{"id":"aqZK9qXRh3fZ"},"id":"aqZK9qXRh3fZ"},{"cell_type":"code","source":["\n","#import json\n","\n","# Raw output from the LLM\n","raw_output4 = audit_result_json4\n","\n","# Clean the output by stripping code block markers\n","cleaned_json4 = raw_output4.strip(\"```json\").strip(\"```\").strip()\n","\n","# Try parsing the cleaned JSON safely\n","try:\n","    audit_result = json.loads(cleaned_json4)\n","    print(json.dumps(audit_result, indent=4))  # Pretty print the output\n","except json.JSONDecodeError as e:\n","    print(\"JSON Decode Error:\", e)\n","    print(\"Raw Output:\", cleaned_json4)  # Print the raw output for debugging\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jXjsGtgCh3O4","executionInfo":{"status":"ok","timestamp":1738952754343,"user_tz":-480,"elapsed":21,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"2a5c9b1a-c544-433c-e23d-b46eb308c3e9"},"id":"jXjsGtgCh3O4","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"audit_results\": [\n","        {\n","            \"criteria\": \"Introduction\",\n","            \"audit_reason\": \"The agent introduced themselves at the start by giving their name and the company they represent.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Acquire Customer Information\",\n","            \"audit_reason\": \"The agent gathered the customer's name, phone number, and apartment number before addressing the complaint.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Politeness and Respect\",\n","            \"audit_reason\": \"The agent maintained a polite and respectful tone throughout the interaction.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Empathy and Understanding\",\n","            \"audit_reason\": \"The agent apologized for the inconvenience and demonstrated understanding of the customer's situation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Gratitude\",\n","            \"audit_reason\": \"The agent thanked the customer at the end of the call.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Provide Conclusion from Customer Request\",\n","            \"audit_reason\": \"The agent summarized the customer's complaint and assured them that the landlord would be contacted.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarifying Questions\",\n","            \"audit_reason\": \"The agent asked the customer for the spelling of their name and confirmed the phone number and apartment number.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarity of Language\",\n","            \"audit_reason\": \"The agent's language was clear, concise, and easy to understand.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Relevance of Information\",\n","            \"audit_reason\": \"The agent provided relevant information by ensuring the customer's complaint would be forwarded to the landlord.\",\n","            \"result\": \"Pass\"\n","        }\n","    ]\n","}\n"]}]},{"cell_type":"markdown","source":["## 5. Real-State-Lead-Gen-1.mp3"],"metadata":{"id":"Q3W1LmD87--o"},"id":"Q3W1LmD87--o"},{"cell_type":"markdown","source":["1. Input audio file to generate the transcript - print the transcript"],"metadata":{"id":"T5ZNMYO4_5Is"},"id":"T5ZNMYO4_5Is"},{"cell_type":"code","source":["\n","# Example Usage\n","audio_file5 = \"Real-State-Lead-Gen-1.mp3\"  # Path to audio file\n","\n","# Step 1: Get transcribed text\n","predicted_transcription5 = transcribe_audio(audio_file5)\n","\n","# Print Result\n","print(\"Predicted Transcription:\", predicted_transcription5)\n"],"metadata":{"id":"Y1BitqMv9iSe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953004029,"user_tz":-480,"elapsed":2377,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"fb2e0a85-2612-462a-a4fb-2d594cf731f6"},"id":"Y1BitqMv9iSe","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Transcription:  Hello, Eloise speaking. Hi, Eloise. This is Sophia. Good day. I'm phoning from the realestateleadgeneration.com.au. We just want to... Yes? Our custom lead generation packages are now live. We're getting real estate agent leads as we speak. Now, I know you're busy, Eloise, But if your team is already set up with a stable stream of incoming leads, property appraisals, property management, and general inquiries, that's fine. We'll leave you to it. But we've been working with real estate agencies for over 10 years, and there's always a common theme. Where is your next lead going to come from? So my call today is just to book a time with one of our real estate lead specialists. We're based in both Sydney and Melbourne. They'll quickly introduce the package to you. Just run through a few of the finer details, Eloise. It'll only take 10 to 20 minutes to give you the background of the package. to let you ask any questions you may have. Are you free next week, Wednesday, during the morning or after lunch? No, I'm really sorry. I'll be running around at open. What about Friday next week Or we can do April appointments as well I don actually understand What is it Custom lead generation package This is your line of business, right? Real estate? Yes. So these are just custom lead generations. To be honest, I don't really have the information for the package. What I really do is just to connect you to our real estate lead specialist so that they could discuss the package with you. any questions that you may have to be able to answer it for you most definitely through the appointment it'll just take like 10 to 20 minutes oh okay um can because i'm like i'm out at the moment are you able to send me an email and i can have a look at it and then confirm a time i won't be because i to be honest i don't really have we call out so i don't really have me email but i could i could set you up for say friday next week and we still have we still have from 10 a.m. to 12.30. No, thanks. Sorry. Okay. What about if I call you back next week and then perhaps we can get an appointment time for you next week? Okay, that sounds good. All right. I'll call you back Monday. All right. Thank you. All right. Thank you so much. Have a good day today. Enjoy your weekend. Okay. Thanks. Bye. Bye.\n"]}]},{"cell_type":"markdown","source":["2. Word Error Rate(WER)\n","\n","Use this module jiwer to compute the WER - print the WER result"],"metadata":{"id":"cLvKrtUj_5Iu"},"id":"cLvKrtUj_5Iu"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file5 = \"Real-State-Lead-Gen-1.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Original\n","wer_score5 = calculate_wer_Ori(ground_truth_file5, predicted_transcription5)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Original:\", wer_score5)\n"],"metadata":{"id":"sDHVGreF_5Iu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953009883,"user_tz":-480,"elapsed":71,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"3bc19b2a-2cc3-493c-ea45-2617a68a0deb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Original: 0.16121495327102803\n"]}],"id":"sDHVGreF_5Iu"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file5 = \"Real-State-Lead-Gen-1.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Normalized\n","wer_score5 = calculate_wer_Norm(ground_truth_file5, predicted_transcription5)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Normalized:\", wer_score5)\n"],"metadata":{"id":"zw9zQVEOoCsr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953054858,"user_tz":-480,"elapsed":42,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"d9ed05ee-1e89-410d-a619-c62bfc10387c"},"id":"zw9zQVEOoCsr","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Normalized: 0.05128205128205128\n"]}]},{"cell_type":"markdown","source":["3. Use the transcript with speakers label perform audit with the criteria then generate the report - print the result"],"metadata":{"id":"jAENmEjr_5Iw"},"id":"jAENmEjr_5Iw"},{"cell_type":"code","source":["\n","# Run the Audit on predicted_transcription5\n","import json\n","\n","# Use the predicted transcription from your speech-to-text model\n","audit_result_json5 = audit_chain.invoke({\"transcription\": predicted_transcription5})\n","\n","#Check if output is empty (for debugging)\n","#print(\"Audit Result JSON Output:\", audit_result_json5)\n"],"metadata":{"id":"O-gt4zqD_5Iw","executionInfo":{"status":"ok","timestamp":1738953144213,"user_tz":-480,"elapsed":5657,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"execution_count":19,"outputs":[],"id":"O-gt4zqD_5Iw"},{"cell_type":"markdown","source":["4. Export the report - print the result"],"metadata":{"id":"Z5-GlAKZh7CE"},"id":"Z5-GlAKZh7CE"},{"cell_type":"code","source":["\n","#import json\n","\n","# Raw output from the LLM\n","raw_output5 = audit_result_json5\n","\n","# Clean the output by stripping code block markers\n","cleaned_json5 = raw_output5.strip(\"```json\").strip(\"```\").strip()\n","\n","# Try parsing the cleaned JSON safely\n","try:\n","    audit_result = json.loads(cleaned_json5)\n","    print(json.dumps(audit_result, indent=4))  # Pretty print the output\n","except json.JSONDecodeError as e:\n","    print(\"JSON Decode Error:\", e)\n","    print(\"Raw Output:\", cleaned_json5)  # Print the raw output for debugging\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6rHdXo4h6cr","executionInfo":{"status":"ok","timestamp":1738953147376,"user_tz":-480,"elapsed":46,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"0cfa0022-e04e-4222-abeb-fb48dca95681"},"id":"B6rHdXo4h6cr","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"audit_results\": [\n","        {\n","            \"criteria\": \"Introduction\",\n","            \"audit_reason\": \"The agent introduced themselves at the start by saying 'Hello, Eloise speaking.'\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Acquire Customer Information\",\n","            \"audit_reason\": \"The agent did not gather any customer details before engaging in the conversation. The customer initiated the identification.\",\n","            \"result\": \"Fail\"\n","        },\n","        {\n","            \"criteria\": \"Politeness and Respect\",\n","            \"audit_reason\": \"The agent was polite and addressed the customer by name. They also closed the conversation with a polite note.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Empathy and Understanding\",\n","            \"audit_reason\": \"The agent acknowledged the customer's busy schedule and showed understanding by offering alternative appointment times.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Gratitude\",\n","            \"audit_reason\": \"The agent expressed gratitude at the end of the conversation by thanking the customer.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Provide Conclusion from Customer Request\",\n","            \"audit_reason\": \"The agent did not summarize the customer's request explicitly.\",\n","            \"result\": \"Fail\"\n","        },\n","        {\n","            \"criteria\": \"Clarifying Questions\",\n","            \"audit_reason\": \"The agent did clarify what their custom lead generation packages were when the customer asked.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarity of Language\",\n","            \"audit_reason\": \"The agent's language was clear, but they struggled to explain the package details due to lack of information.\",\n","            \"result\": \"Partial Pass\"\n","        },\n","        {\n","            \"criteria\": \"Relevance of Information\",\n","            \"audit_reason\": \"The agent provided information relevant to setting up an appointment but was unable to provide detailed information about the package.\",\n","            \"result\": \"Partial Pass\"\n","        }\n","    ]\n","}\n"]}]},{"cell_type":"markdown","source":["## 6. Travel-Reservation.mp3"],"metadata":{"id":"AD8b2ydm8TyW"},"id":"AD8b2ydm8TyW"},{"cell_type":"markdown","source":["1. Input audio file to generate the transcript - print the transcript"],"metadata":{"id":"DIZPVFMP_7yO"},"id":"DIZPVFMP_7yO"},{"cell_type":"code","source":["\n","# Example Usage\n","audio_file6 = \"Travel-Reservation.mp3\"  # Path to audio file\n","\n","# Step 1: Get transcribed text\n","predicted_transcription6 = transcribe_audio(audio_file6)\n","\n","# Print Result\n","print(\"Predicted Transcription:\", predicted_transcription6)\n"],"metadata":{"id":"kzG49kSb9pHt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953431304,"user_tz":-480,"elapsed":3350,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"3c0e7255-cf12-4f69-d3e2-857a7015dfe1"},"id":"kzG49kSb9pHt","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Transcription:  Hi, thank you for calling Hotel California. This is Candice. How may I help you? Hi, Candice. This is Stephen. I'd like to book for four people, please. And that would be for August 18th. Sure, Stephen. I'd be happy to help you with that. So, which room do you have in mind? Actually, I got to tell you first that I am super busy. So I haven't been able to browse through your website. And I don't know, I don't really know the rooms you have right now. But I could give you my requirements and then you suggest the best rooms for me. Could we do that? Absolutely. What do you need? So there are four of us, including me. and we need something with a wi-fi and maybe a swimming pool got it will you four be staying in one room or separate rooms oh sorry i forgot to tell you um that would be separate because you see we two couples so we need two rooms I see So in that case I recommend two deluxe kings Each room has a king-size bed, which fits two people, a Wi-Fi, and access to a swimming pool, and free lunch and breakfast. All of these for $200 each. And that's going to be $400 for two rooms. How does it sound? Oh, that is a bit too much. That's a bit expensive. Actually, do you maybe have something more affordable than that? It's just that now that I think about it, I remember there's a beach close to your hotel. So we will probably just take a trip there and you can take out the swimming pool. Is that possible? Sure. Let me see your options here. So if you want to take out the swimming pool and just have the Wi-Fi, then we certainly have a room for that. And that is the classic king for each which is for two rooms as opposed to And you still going going to get the king bed and the Wi But I have to tell you Stephen aside from having no swimming pool you will also only get a free breakfast instead of lunch and breakfast. Is that okay with you? Perfect. Perfect, Candice. That's exactly what we need. We'll be having lunch at the beach anyway, so we won't be eating at the hotel. all. So to Classic King it is. Do you need my credit card number or what do you need? For security purposes, we don't really take credit card info over the phone. But what I need from you instead is your email address where I can send you a link where you can securely pay and enter your card information. Okay, cool. You can send it to Stephen underscore 182 at gmail.com. Thank you. How do you spell Stephen, by the way? Is that a Stephen with a V or a Stephen with a P? That's with a P for Pepper. Thank you So just to make sure let me just spell that out for you That is S for Sierra T for Tango E for Echo P for Peter H for Hotel and for Nancy underscore 182 at gmail Yep that correct Okay perfect So just to recap you will be booking two classic kings this August 18, 2020. And the total amount is $250 for two rooms. Are all of these correct? Yep, all correct. Thank you, Stephen. So after this call, you should receive an email from booking at calihotel.com. And that email is a secure link where you can click and enter your full name and card info. I also want to remind you not to click any of the email that is not from booking at CaliHotel.com because we only take payments through this one email. All right? Gotcha. So is there anything else that I can help you with today? Nope. You've been very helpful, Candice. Thank you so much. You're most welcome, Stephen. Thank you for calling Hotel California. you have a great day have a great day Candice bye\n"]}]},{"cell_type":"markdown","source":["2. Word Error Rate(WER)\n","\n","Use this module jiwer to compute the WER - print the WER result"],"metadata":{"id":"UYq8GooN_7yP"},"id":"UYq8GooN_7yP"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file6 = \"Travel-Reservation.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Original\n","wer_score6 = calculate_wer_Ori(ground_truth_file6, predicted_transcription6)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Original:\", wer_score6)\n"],"metadata":{"id":"Xy_3TLNV_7yP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953435237,"user_tz":-480,"elapsed":56,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"0bcd9c0c-8944-4728-f8fc-59cca1c2d3d9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Original: 0.11403508771929824\n"]}],"id":"Xy_3TLNV_7yP"},{"cell_type":"code","source":["\n","# Example Usage\n","ground_truth_file6 = \"Travel-Reservation.txt\"  # Path to ground truth transcript\n","\n","# Step 2: Compute WER - Normalized\n","wer_score6 = calculate_wer_Norm(ground_truth_file6, predicted_transcription6)\n","\n","# Print Result\n","print(\"\\nWord Error Rate (WER) - Normalized:\", wer_score6)\n"],"metadata":{"id":"mUPg8edsoE9V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738953439017,"user_tz":-480,"elapsed":35,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"eda046ac-dc21-4639-c127-00c66c4256b1"},"id":"mUPg8edsoE9V","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Error Rate (WER) - Normalized: 0.029239766081871343\n"]}]},{"cell_type":"markdown","source":["3. Use the transcript with speakers label perform audit with the criteria then generate the report - print the result"],"metadata":{"id":"RD3Q_DZo_7yP"},"id":"RD3Q_DZo_7yP"},{"cell_type":"code","source":["\n","# Run the Audit on predicted_transcription6\n","import json\n","\n","# Use the predicted transcription from your speech-to-text model\n","audit_result_json6 = audit_chain.invoke({\"transcription\": predicted_transcription6})\n","\n","#Check if output is empty (for debugging)\n","#print(\"Audit Result JSON Output:\", audit_result_json6)\n"],"metadata":{"id":"5h1ZABN0_7yP","executionInfo":{"status":"ok","timestamp":1738953502138,"user_tz":-480,"elapsed":4315,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}}},"execution_count":18,"outputs":[],"id":"5h1ZABN0_7yP"},{"cell_type":"markdown","source":["4. Export the report - print the result"],"metadata":{"id":"0zHImQF1iOsq"},"id":"0zHImQF1iOsq"},{"cell_type":"code","source":["\n","#import json\n","\n","# Raw output from the LLM\n","raw_output6 = audit_result_json6\n","\n","# Clean the output by stripping code block markers\n","cleaned_json6 = raw_output6.strip(\"```json\").strip(\"```\").strip()\n","\n","# Try parsing the cleaned JSON safely\n","try:\n","    audit_result = json.loads(cleaned_json6)\n","    print(json.dumps(audit_result, indent=4))  # Pretty print the output\n","except json.JSONDecodeError as e:\n","    print(\"JSON Decode Error:\", e)\n","    print(\"Raw Output:\", cleaned_json6)  # Print the raw output for debugging\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1c6cAv-4iOcU","executionInfo":{"status":"ok","timestamp":1738953504839,"user_tz":-480,"elapsed":23,"user":{"displayName":"Nursharinah Sohaimi","userId":"16997412309207229857"}},"outputId":"e286fd91-617e-4957-92d4-35f0a8927115"},"id":"1c6cAv-4iOcU","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"audit_results\": [\n","        {\n","            \"criteria\": \"Introduction\",\n","            \"audit_reason\": \"The agent introduced themselves at the start.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Acquire Customer Information\",\n","            \"audit_reason\": \"The agent gathered the customer's name and requirements before proceeding with the booking.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Politeness and Respect\",\n","            \"audit_reason\": \"The agent was polite and used professional language throughout the conversation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Empathy and Understanding\",\n","            \"audit_reason\": \"The agent demonstrated understanding and was accommodating to the customer's busy schedule and specific needs.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Gratitude\",\n","            \"audit_reason\": \"The agent expressed gratitude at the start and end of the conversation.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Provide Conclusion from Customer Request\",\n","            \"audit_reason\": \"The agent summarized the customer's request and confirmed the booking details.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarifying Questions\",\n","            \"audit_reason\": \"The agent asked clarifying questions to ensure accuracy of the customer's email and requirements.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Clarity of Language\",\n","            \"audit_reason\": \"The agent\\u2019s language was clear, concise, and easy to understand.\",\n","            \"result\": \"Pass\"\n","        },\n","        {\n","            \"criteria\": \"Relevance of Information\",\n","            \"audit_reason\": \"The agent provided relevant information regarding room options, prices, and payment process.\",\n","            \"result\": \"Pass\"\n","        }\n","    ]\n","}\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}